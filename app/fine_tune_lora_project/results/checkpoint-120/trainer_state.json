{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 120,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.25,
      "grad_norm": 6.353864669799805,
      "learning_rate": 0.00018333333333333334,
      "loss": 0.6859,
      "step": 10
    },
    {
      "epoch": 0.5,
      "grad_norm": 5.999237060546875,
      "learning_rate": 0.0001666666666666667,
      "loss": 0.6788,
      "step": 20
    },
    {
      "epoch": 0.75,
      "grad_norm": 12.155627250671387,
      "learning_rate": 0.00015000000000000001,
      "loss": 0.6184,
      "step": 30
    },
    {
      "epoch": 1.0,
      "grad_norm": 4.653249740600586,
      "learning_rate": 0.00013333333333333334,
      "loss": 0.5051,
      "step": 40
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.45062321424484253,
      "eval_runtime": 1.453,
      "eval_samples_per_second": 27.528,
      "eval_steps_per_second": 13.764,
      "step": 40
    },
    {
      "epoch": 1.25,
      "grad_norm": 3.287245512008667,
      "learning_rate": 0.00011666666666666668,
      "loss": 0.3427,
      "step": 50
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.9682276248931885,
      "learning_rate": 0.0001,
      "loss": 0.2139,
      "step": 60
    },
    {
      "epoch": 1.75,
      "grad_norm": 1.1150598526000977,
      "learning_rate": 8.333333333333334e-05,
      "loss": 0.092,
      "step": 70
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.7278651595115662,
      "learning_rate": 6.666666666666667e-05,
      "loss": 0.0374,
      "step": 80
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.027951184660196304,
      "eval_runtime": 1.5049,
      "eval_samples_per_second": 26.58,
      "eval_steps_per_second": 13.29,
      "step": 80
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.37166526913642883,
      "learning_rate": 5e-05,
      "loss": 0.0307,
      "step": 90
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.36745694279670715,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 0.0152,
      "step": 100
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.29426953196525574,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 0.0104,
      "step": 110
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.26920995116233826,
      "learning_rate": 0.0,
      "loss": 0.0106,
      "step": 120
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.011623787693679333,
      "eval_runtime": 1.4547,
      "eval_samples_per_second": 27.497,
      "eval_steps_per_second": 13.748,
      "step": 120
    }
  ],
  "logging_steps": 10,
  "max_steps": 120,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "total_flos": 126730439884800.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
